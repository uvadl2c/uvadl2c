[
	{
		"type": "Lecture",
		"name": "Module 1: Group equivariant deep learning",
		"date": "<b>Erik Bekkers </b>",
		"credit": "2 credits",
		"desc": "<b>Credits: 2pts</b> <br></br> This module covers the topic of geometric deep learning, touching upon all its five G's (Grids, Groups, Graphs, Geodesics, and Gauges) but with a strong focus on group equivariant deep learning. The impact that CNNs made in fields such as computer vision, computational chemistry and physics, can largely be attributed to the fact that convolutions allow for weight sharing, geometric stability, and a dramatic decrease in learnable parameters by leveraging symmetries in data and architecture design. These enabling properties arise from the equivariance property of convolutions. In this module you will learn how to equip neural networks with equivariance properties. The module is split in 4 lectures with accompanying tutorials: This module is split into 4 lectures: <ul><li> <b>Lecture 1</b>: Regular group convolutional neural networks (G-CNNs). In this lecture we cover the basics of group convolutional NNs and show how to leverage symmetries in data and practical problems.</li>  <li> <b>Lecture 2</b>: Steerable G-CNNs. In this lecture we introduce a very general class of G-CNNs that allows to handle (rotational) symmetries in a flexible and powerful way. These methods are at the core of the most successful methods to handle 3D data such as atomic point clouds, but are also at the core of gauge equivariant methods that are applicable to arbitrary Riemannian manifolds.</li> <li> <b>Lecture 3</b>: Equivariant graph NNs. Many problems in computational chemistry and computational physics are now-a-days solved via graph NNs. The SotA in these domains derive their effectives from the geometric structure and symmetries presented by the data and underlying physics. In this lecture cover tools for SE(3) equivariance in the context of state-of-the-art in geometric graph NNs. </li> <li> <b>Lecture 4</b>: Recap and/or, if time allows, further exploration of topics covered in this module (e.g. equivariant transformers, geometric latent spaces, â€¦). </li> </ul> <br></br> All the lectures can be find here: https://uvagedl.github.io/",
		"documents": [
		
			{"name": "First lecture (TBA)",
				 "link": "https://uvagedl.github.io/lectures_pdf/Lecture_1_1_Motivation.pdf",
				 "type": "pdf"},
			{"name": "GDL - Lecture 2.1: Steerable kernels/basis functions",
				 "link": "lectures/SSL/Lecture_2_1.pdf",
				 "type": "pdf"},
			{"name": "GDL - Lecture 2.2: Revisiting Regular G-Convs with Steerable Kernels",
				 "link": "lectures/SSL/Lecture_2_2.pdf",
				 "type": "pdf"},
			{"name": "GDL - Lecture 2.3: Group Theory (Irreducible representations, Fourier)",
				 "link": "lectures/SSL/Lecture_2_3.pdf",
				 "type": "pdf"},
			{"name": "GDL - Lecture 2.4: Group Theory (Induced representation, feature fields)",
				 "link": "lectures/SSL/Lecture_2_4.pdf",
				 "type": "pdf"},
			{"name": "GDL - Lecture 2.5: Steerable group convolutions",
				 "link": "lectures/SSL/Lecture_2_5.pdf",
				 "type": "pdf"},
			{"name": "GDL - Lecture 2.6: Activation Functions for Steerable G-CNNs",
				 "link": "lectures/SSL/Lecture_2_6.pdf",
				 "type": "pdf"},
			{"name": "GDL - Lecture 2.7: Derivation of Harmonic Networks from Regular G-Convs",
				 "link": "lectures/SSL/Lecture_2_7.pdf",
				 "type": "pdf"}
				 
			],
			"recordings": [
			{"name": "First lecture",
				 "link": "https://www.youtube.com/watch?v=4ejWLiX4sqo",
				 "type": "video"},
			{"name": "Lecture 2.1: Steerable kernels/basis functions",
				 "link": "https://www.youtube.com/watch?v=Lm5vZRtGysc&list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd&index=8&t=1s&ab_channel=ErikBekkers",
				 "type": "video"},
			{"name": "Lecture 2.2: Revisiting Regular G-Convs with Steerable Kernels",
				 "link": "https://www.youtube.com/watch?v=OHFwsEglmrE&list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd&index=9&ab_channel=ErikBekkers",
				 "type": "video"},
			{"name": "Lecture 2.3: Group Theory (Irreducible representations, Fourier)",
				 "link": "https://www.youtube.com/watch?v=qnqcLumE3vg&list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd&index=10&ab_channel=ErikBekkers",
				 "type": "video"},
			{"name": "Lecture 2.4: Group Theory (Induced representation, feature fields)",
				 "link": "https://www.youtube.com/watch?v=lkXO0Zi65Uc&list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd&index=11&ab_channel=ErikBekkers",
				 "type": "video"},
			{"name": "Lecture 2.5: Steerable group convolutions",
				 "link": "https://www.youtube.com/watch?v=sDpdtKHgDbE&list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd&index=12&ab_channel=ErikBekkers",
				 "type": "video"},
			{"name": "Lecture 2.6: Activation Functions for Steerable G-CNNs",
				 "link": "https://www.youtube.com/watch?v=b8K6adf_zY0&list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd&index=13&ab_channel=ErikBekkers",
				 "type": "video"},
			{"name": "Lecture 2.7: Derivation of Harmonic Networks from Regular G-Convs",
				 "link": "https://www.youtube.com/watch?v=EBzqL1OXigM&list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd&index=14&ab_channel=ErikBekkers",
				 "type": "video"}
	
			]
	},

	{
		"type": "Lecture",
		"name": "Module 2: Bayesian Deep Learning",
		"date": "<b> Eric Nalisnick </b>",
		"credit": "1 credit",
		"desc": "<b>Credits: 1pts </b><br></br> For principled decision making, it is usually not enough to have our models produce only point predictions.  Safety-critical scenarios require tracking and communicating the corresponding uncertainty in that prediction. These uncertainties are then useful for, among other things, knowing when a system should not be trusted. This could be because the system is operating in anomalous conditions or simply because a decision is inherently difficult. In either case, if the uncertainty outputs are sufficiently high, we could stop the system and call upon a human for help. For example, in the setting of autonomous driving, this could mean passing off control to a human driver. Other options would be to slow down the car, collect more data, activate other sensors, etc. In modern computer vision systems based off deep learning, quantifying uncertainty is especially challenging since many classical techniques (e.g. asymptotic distribution of an estimator) cannot be applied. Thus there is often an inherent tradeoff between exploiting the predictive power of deep learning and having principled uncertainty estimates.  This module explores the tension between principled uncertainty quantification and computational tractability, covering Bayesian neural networks, scalable approximate inference, and recent alternatives such as conformal inference. <ul><li> <b>Lecture 1: First lecture on Bayesian Deep Learning and Uncertainty Quantification</b>: </li><li> <b>Lecture 2: Second lecture on Bayesian Deep Learning and Uncertainty Quantification</b>: </li></ul>",
		"documents": [
		
			{"name": "First lecture on Bayesian Deep Learning and Uncertainty Quantification",
				 "link": "lectures/Bayesian Deep Learning/DL2_BNN_module.pdf",
				 "type": "pdf"},

				 {"name": "Second lecture on Bayesian Deep Learning and Uncertainty Quantification",
				 "link": "lectures/Bayesian Deep Learning/DL2_BNN_module_part2.pdf",
				 "type": "pdf"} 
				 
			],
			"recordings": [
				{"name": "First lecture on Bayesian Deep Learning and Uncertainty Quantification",
				"link": "https://youtu.be/7iEmKqe7w3A",
				"type": "video"},
			{"name": "Second lecture on Bayesian Deep Learning and Uncertainty Quantification",
				 "link": "https://youtu.be/CSbKS2OsDrQ",
				 "type": "video"}
	
			]
	},

	{
		"type": "Module",
		"name": "Module 3: Deep probabilistic models",
		"date": "<b>Wilker Aziz Ferreira</b>",
		"credit": "1 credit",
		"desc": "<b>Credits: 1pts</b><br></br> Many (if not most) advanced DL models are probabilistic models (or at the very least key aspects of their design and training are given probabilistic treatment). The focus of this module (or this part of the module) is to learn to prescribe probability distributions over complex sample spaces (discrete, continuous, structured), parameterise these distributions using NNs, and estimate model parameters to maximise (bounds on) likelihood via gradient descent. The goal is to get students to expand their toolbox, to see modelling ideas and estimation algorithms as modules they can compose (ie, VI is not exclusive to VAEs, VAEs are not necessarily built upon Gaussians, autoregressive models are not exclusive to one data type or another, reparameterisation is a general tool, MLE is a general tool, etc). We cover two main classes of models, depending on whether a key function (the likelihood function) can be assessed tractably given a set of observations and a parameter vector. <br></br> <b>TL;DR</b> In this module you learn to view data as a byproduct of probabilistic experiments. You will parameterise joint probability distributions over observed random variables, however complex/structured they may be, and perform parameter estimation by regularised gradient-based maximum likelihood estimation. </br> <br><b>Relationship to other modules:</b></br> <ul><li>Advanced generative models are (rather special) instances of probabilistic models, this module gives you some background knowledge that can ease your way into advanced generative models such as normalising flows, energy-based models and diffusion processes.</li> <li>Certain advanced probabilistic models (e.g., latent variable models) require techniques to approximate intractable computations in a principled manner, those techniques are discussed in the amortised variational inference module. Because amortised VI concerns probabilistic models, this module can be thought of as background to it.</li><li>Bayesian models are also probabilistic, but you don't necessarily need to content of this module to understand Bayesian deep learning (it does help, but you can live without).</li></ul>",
		"documents": [
		
			{"name": "First lecture",
				 "link": "https://probabll.github.io/slides/DL2/2023/probdl-1.pdf",
				 "type": "pdf"},

				 {"name": "Second lecture",
				 "link": "https://probabll.github.io/slides/DL2/2023/probdl-2.pdf",
				 "type": "pdf"}
				 
			],
			"recordings": [
			{"name": "First lecture",
				 "link": "https://canvas.uva.nl/courses/36137/pages/deep-probabilistic-models?module_item_id=1621171",
				 "type": "video"},

				 {"name": "Second lecture",
				 "link": "https://canvas.uva.nl/courses/36137/pages/deep-probabilistic-models?module_item_id=1621171",
				 "type": "video"}
	
			]
	},


	{
		"type": "Lecture",
		"name": "Module 4: Causality and causal representation learning",
		"date": "<b>Sara Magliacane</b>",
		"credit": "2 credits",
		"desc": "<b>Credits: 2pts</b> <br></br> This module covers the topic of causality and its connections to DL, including the emerging field of causal representation learning. In real-world settings, there are many issues that are often neglected in standard machine learning courses. In this module we will focus on the following two aspects: <br></br> (i) many tasks are inherently trying to answer causal questions and gather actionable insights, even when there is not enough data to draw causal conclusions; <br></br> (ii) the distribution of the data can shift across tasks and time. <br></br> We will focus on the first issue in the first two lectures, in which we will first introduce the basic concepts in causality (e.g. d-separation, causal graphs, interventions) and then focus on the task of causal discovery (i.e. learning causal relations from data), starting with classic approaches and then moving to neural causal discovery. We will then turn to the second issue and discuss how ideas from causality help DL and RL, allowing us to reason systematically about distribution shifts and nonstationarity. Finally, we will focus on learning causal representations from high-dimensional data, e.g. sequences of images, which will be intuitively more robust to changes in the environment. This will also be the topic of the tutorial, in which we will focus on an instance of causal representation learning method. To summarise the lectures will be split as follows: <br></br><ul><li>Lecture 1: Introduction to causality, Correlation vs causation, Simpson's paradox</li> <li>Lecture 2: Causal discovery: classic approaches and neural causal discovery</li> <li>Lecture 3: Causality-inspired ML: how can ideas from causality help ML?</li><li>Lecture 4: Causal representation learning: learning causal representations from high-dimensional data</li></ul>",
		"documents": [
		
			{"name": "First lecture: 1.1 Introduction to causality",
				 "link": "https://canvas.uva.nl/courses/36137/files/8505342?module_item_id=1623072",
				 "type": "pdf"},
			{"name": "First lecture: 1.2 Graphical models",
				"link": "https://canvas.uva.nl/courses/36137/files/8505343?module_item_id=1623073",
				"type": "pdf"},
			{"name": "First lecture: 1.3 Graphical models",
				"link": "https://canvas.uva.nl/courses/36137/files/folder/lectures/Causality%20and%20Deep%20Learning?preview=8505341",
				"type": "pdf"},
			{"name": "Second lecture: 2.1 Graphical models",
				"link": "https://canvas.uva.nl/courses/36137/files/folder/lectures/Causality%20and%20Deep%20Learning?preview=8557600",
				"type": "pdf"},
			{"name": "Second lecture: 2.2 Graphical models",
				"link": "https://canvas.uva.nl/courses/36137/files/folder/lectures/Causality%20and%20Deep%20Learning?preview=8557682",
				"type": "pdf"}
				 
			],
			"recordings": [
			{"name": "First lecture: 1.1 Introduction to causality",
				 "link": "https://canvas.uva.nl/courses/36137/modules/items/1623258",
				 "type": "video"},
			{"name": "First lecture: 1.2 Graphical models",
				 "link": "https://canvas.uva.nl/courses/36137/modules/items/1623260",
				 "type": "video"},
			{"name": "First lecture: 1.3 Causal graphs",
				 "link": "https://video.uva.nl/media/DL2%20-%20Causality%20and%20DL%3A%201.3%20Causal%20graphs/0_yorbvyqr",
				 "type": "video"},
			{"name": "Second lecture: 2.1 Causal discovery",
				 "link": "https://video.uva.nl/media/DL2%20-%20Causality%20and%20DL%3A%20%202.1%20Causal%20Discovery/0_zrh0q1st",
				 "type": "video"},
			{"name": "Second lecture: 2.2 Neural Causal Discovery (and a part of 2.1)",
				 "link": "https://video.uva.nl/media/DL2%20-%20Causality%20and%20DL%3A%20%202.2%20Neural%20Causal%20Discovery%20(and%20a%20part%20of%202.1)/0_tcu1cjba",
				 "type": "video"}
	
			]
	},


	{
		"type": "Lecture",
		"name": "Module 5: Deep Generative Models",
		"date": "<b>Efstratios Gavves</b>",
		"credit": "3 credits",
		"desc": "<b>Credits: 3pts </b><br></br> In this module we will study how one can integrate complex structure into neural networks. We will start with a quick introduction to Monte-Carlo simulation for neural networks. We will discuss Gumbel-Softmax  for differentiable models and the Gumbel-Argmax trick for sampling from categorical distributions, as well as then the Gumbel-Straight-Through variation. We will continue with subset sampling with Gumbel-Topk relaxations, sampling graphs in latent spaces in relational inference with GNN encoder/decode, as well as asampling latent permutations with Gumbel-Sinkhorn. Last, we will discuss about how discrete and continuous sampling connects to analysis of functions from mathematics.",
		"documents": [
		
			{"name": "First lecture",
				 "link": "lectures/DAGM/dgm-intro.pdf",
				 "type": "pdf"},
			{"name": "Second-Third lecture",
				 "link": "lectures/DAGM/dgm-lecture_2-3.pdf",
				 "type": "pdf"}
				 
			],
			"recordings": [
			{"name": "First lecture part A",
				 "link": "https://youtu.be/KQ04vt7f9bw",
				 "type": "video"},
			
				 {"name": "First lecture part B",
				 "link": "https://youtu.be/84ZDpAw6hr0",
				 "type": "video"},
			
				 {"name": "Second lecture part A",
				 "link": "https://youtu.be/c4Xg1IefKfs",
				 "type": "video"},

				 {"name": "Second lecture part B",
				 "link": "https://youtu.be/n1RAlrChleI",
				 "type": "video"}
	
			]
	},


	{
		"type": "Lecture",
		"name": "Module 6: Neural Networks Dynamical Systems",
		"date": "<b>Efstratios Gavves</b>",
		"credit": "1 credits",
		"desc": "<b>Credits: 1pts </b> <br></br> In this module we will study the interface and overlap between neural networks, dynamical systems, ordinary/partial/stochastic differential equations, and physics-based neural networks. We will study how and where dynamical systems be found in neural networks with implicit functions and neural ODEs. We will also see how neural networks can be used to model dynamical systems like Navier-Stokes with physics-informed neural networks, as well as with Fourier-inspired architectures and autoregressive neural networks.",
		"documents": [


		],
		"recordings": [
		]
	},

	{
		"type": "Lecture",
		"name": "Module 7: Self-supervised and Vision-Language Learning",
		"date": "<b>Yuki Asano</b>",
		"credit": "1 credit",
		"desc": "<b> Credits: 1pts </b><br></br> The recent trend of multi-modal learning from vision-language data demonstrates the abilities that can be unlocked by combining these modalities with ever increasing scale. Just in the last few months, models such as GPT-4, Flamingo, CLIP, FROMAGe have shown that in particular the combination with large language models (LLMs) is a key recipe for emerging capabilities of such models such as few-shot and in-context learning or zero-shot performances. In this module, we will focus on the intersection of self-supervised and multi-modal learning techniques that build the technical foundation for these recent achievements and methodologies. This then will allow us to understand and build on top of recent models that are available via APIs. <ul><li> <b>Lecture 1</b>: Refresh and extend the knowledge of self-supervised learning from DL1 to dive deeply into current approaches such as dense self-supervised learning and generative pretraining.</li><li> <b>Lecture 2:</b>: Explore the frontiers of vision-language methodologies, highlighting both the connection to self-supervised principles and the flexibility that comes from using language. We will specifically focus on the emergence and task of in-context learning.</li></ul>",
		"documents": [
		
			{"name": "Self-supervised and Vision-Language Learning (First lecture)",
				 "link": "lectures/SSL/lecture1.pdf",
				 "type": "pdf"},
			
			{"name": "Self-supervised and Vision-Language Learning (Second lecture)",
				"link": "lectures/SSL/lecture2.pdf",
				"type": "pdf"}
				 
			],
			"recordings": [
			{"name": "Self-supervised and Vision-Language Learning (First lecture)",
				 "link": "https://www.youtube.com/watch?v=6P29b2UvVTg",
				 "type": "video"},
				 {"name": "Self-supervised and Vision-Language Learning (Second lecture)",
				 "link": "https://www.youtube.com/watch?v=pvljSifaAIg&ab_channel=YukiAsano",
				 "type": "video"}
	
			]
	},
	{
		"type": "Lecture",
		"name": "Module 8: Amortised Variational Inference",
		"date": "<b>Wilker Aziz Ferreira</b>",
		"credit": "1 credit",
		"desc": "<b> Credits: 1pts </b><br></br> In this module you learn about variational inference (VI), an approximate inference technique that helps us learn models that account for both observed and unobserved random variables. In particular, you will learn about amortised VI, a form of VI where we use neural networks to approximate crucial queries in probabilistic inference, and which can be trained via stochastic gradient optimisation. We will cover two main types of gradient estimators: the score function estimator, which is general estimator and hence can be applied for any well-defined latent variable model, and the reparameterised gradient estimator, which is specific to continuous latent variables (or continuous relaxations of discrete random variables). <br></br> <b>Relationship to other modules:</b> <br></br> The module Deep Probabilistic Models offers background to this module. This module offers background that can be useful for some Deep Generative Models, in particular those that are based on marginalisation of latent variables (e.g., VAEs, diffusion processes). While that module focuses on the different types of deep generative models, some of which require approximate inference for tractable estimation (e.g., VAEs, diffusion processes), this module focuses on approximate inference, variational inference specifically, as a general tool. <br></br> <b>Format:</b><br>the lectures will be live-recorded on-site (recording shared after class), the tutorials will use Jupyter notebook and I will provide support on-site.</br>",
		"documents": [

		],
		"recordings": [

		]
	},

	{
		"type": "Lecture",
		"name": "Guest Lecture: Industry and deep learning (Qualcomm)",
		"date": "<b>Johann Brehmer, Ties van Rozendaal and Jens Petersen</b>",

		"desc": "<b> From causality to compression: AI Research at Qualcomm </b><br></br> Wednesday 26th of April from 11:00-15:00 (SP C0.05). <br></br> What kind of research happens in the industry labs in Amsterdam? We give an overview over the research program at Qualcomm AI Research, just hundreds of meters away in Science Park. After a broad introduction, we focus on two areas: fundamental research in causality and how AI research is enabling next-gen image and video compression codecs. <br></br> In the causality part, we give examples for how causal reasoning and deep learning can help each other. First, we show how machine learning can be used to identify the causal structure of the world when we have non-iid data. We then demonstrate that scale isn't always all you need, and that a causal perspective on the learning process can solve problems that even infinite data cannot solve. <br></br> In the compression part, we introduce the basic ideas of neural compression. We then demonstrate that overfitting can be a good thing: finetuning a network on each video and then storing the finetuned network weights in the compressed file can make codecs more efficient. Finally, we turn towards perceptual compression and show that AI-based codecs can be optimized to look more realistic than conventional methods.",
		"documents": [
		
			{"name": "Qualcomm guest lecture part A (causality)",
				 "link": "lectures/Qualcomm_part_A.pdf",
				 "type": "pdf"}
				 
			],
			"recordings": [
			{"name": "Self-supervised and Vision-Language Learning (First lecture)",
				 "link": "https://www.youtube.com/watch?v=6P29b2UvVTg",
				 "type": "video"}
	
			]
	}

]
