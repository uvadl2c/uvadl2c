<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>UvA Deep Learning II Course</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="css/bootstrap.min.css" type="text/css">

    <!-- Custom Fonts -->
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css" type="text/css">

    <!-- Plugin CSS -->
    <link rel="stylesheet" href="css/animate.min.css" type="text/css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="css/creative.css" type="text/css">

    <link rel="apple-touch-icon" sizes="57x57" href="icons/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="icons/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="icons/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="icons/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="icons/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="icons/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="icons/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="icons/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="icons/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192"  href="icons/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="icons/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="icons/favicon-16x16.png">
    <link rel="manifest" href="/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="icons/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-86672135-1', 'auto');
  ga('send', 'pageview');

</script>

<body id="page-top">

    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">UvA Deep Learning II Course</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a class="page-scroll" href="#about">About</a>
                    </li>

                    <li>
                        <a class="page-scroll" href="#lectures">Lectures</a>
                    </li>

                    <li>
                        <a class="page-scroll" href="#practicals">Tutorials</a>
                    </li>

                    <li>
                        <a class="page-scroll" href="#old-lectures">Old materials</a>
                    </li>
                        
                   
                    <li>
                        <a class="page-scroll" href="#course-links">Links</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#contact">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <header>
        <div class="header-content">
            <div class="header-content-inner">
                <h1>UVA Deep Learning II Course</h1>
                <hr>
                <p>MSc in Artificial Intelligence for the University of Amsterdam.</p>
                <a href="#about" class="btn btn-primary btn-xl page-scroll">Find Out More</a>
            </div>
        </div>
    </header>

    <section class="bg-primary" id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading">About</h2>
                    <hr class="light">
                    <p class="text-faded" style="text-align:justify">Deep learning II is taught in the MSc program in Artificial Intelligence of the University of Amsterdam. In this course we study the theory of deep learning, namely of modern, multi-layered neural networks trained on big data. The course is coordinated by <a href="mailto: e.gavves@uva.nl" style="color: white;">Efstratios Gavves</a>, <a href="mailto: e.j.bekkers@uva.nl" style="color: white;">Erik Bekkers</a>, <a href="mailto: W.FerreiraAziz@uva.nl" style="color: white;">Wilker Aziz Fereira </a> and <a href="mailto: c.athanasiadis@uva.nl" style="color: white;">Christos Athanasiadis</a>.
                        
                        <br></br>
                        <a href="mailto: e.gavves@uva.nl""><img class="img-circle" src="images/people/efstratios-gavves.png" hspace="5" width="120" title="Efstratios Gavves"></a>
                            <a href="mailto: W.FerreiraAziz@uva.nl""><img class="img-circle" src="images/people/wilker-aziz-fereira.png" hspace="5" width="120" title="Wilker-Aziz-Fereira"></a>
                            <a href="mailto: e.j.bekkers@uva.nl""><img class="img-circle" src="images/people/erik.jpg" hspace="5" width="120" title="Erik Bekkers"></a>
                            <a href="mailto: c.athanasiadis@uva.nl""><img class="img-circle" src="images/people/christos-athanasiadis.jpg" hspace="5" width="120" title="Christos Athanasiadis"></a>
                        <br></br>
                            <!-- And the lectures for the course are: Erik Bekkers, Eric Nalisnick, Sara Magliacane, Yuki Asano, Wilker Aziz Ferreira and Stratis Gaves. 
                            <br></br>
                            <a href="mailto: e.gavves@uva.nl""><img class="img-circle" src="images/people/efstratios-gavves.png" hspace="5" width="120" title="Efstratios Gavves"></a>
                            <a href="mailto: W.FerreiraAziz@uva.nl""><img class="img-circle" src="images/people/wilker-aziz-fereira.png" hspace="5" width="120" title="Wilker-Aziz-Fereira"></a>
                            <a href="mailto: e.j.bekkers@uva.nl""><img class="img-circle" src="images/people/erik.jpg" hspace="5" width="120" title="Erik Bekkers"></a>
                            <a href="mailto: e.t.nalisnick@uva.nl""><img class="img-circle" src="images/people/eric.jpg" hspace="5" width="120" title="Eric Nalisnick"></a>
                            <a href="mailto: s.magliacane@uva.nl""><img class="img-circle" src="images/people/sara.jpg" hspace="5" width="120" title="Sara Magliacane"></a>
                            <a href="mailto: y.m.asano@uva.nl""><img class="img-circle" src="images/people/yuki.jpg" hspace="5" width="120" title="Yuki Asano"></a>

                        <br></br>  -->
                    The Teaching Assistants (TAs) are:
                    <a href='mailto:c.athanasiadis@uva.nl' target='_blank' style='color: white;'>Christos Athanasiadis</a>
                </p>
                   

                    <br></br>
                    <a href='mailto:c.athanasiadis@uva.nl'><img class='img-circle' src='images/people/christos-athanasiadis.jpg' hspace='5' width='120' alt='Christos Athanasiadis' title='Christos Athanasiadis'></a>
                </div>
            </div>
        </div>
    </section>

    <section id="lectures">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Lectures</h2>
                    <hr class="primary">
                </div>
            </div>

            <div class="lecture-box" style="margin-bottom: 40px;">
                <button type="button" class="lecture-collapsible"><span class="fa fa-2x fa-university text-primary"></span><span class="lecture-title">First part: Group equivariant deep learning</span></button>
                <div class="lecture-content">
                    <div class="padding-div">
                        <p class="text-muted" style="font-size: 12px"><b>Erik Bekkers </b></p>
                        <p><b>Credits: 2pts</b> <br></br> This module covers the topic of geometric deep learning, touching upon all its five G's (Grids, Groups, Graphs, Geodesics, and Gauges) but with a strong focus on group equivariant deep learning. The impact that CNNs made in fields such as computer vision, computational chemistry and physics, can largely be attributed to the fact that convolutions allow for weight sharing, geometric stability, and a dramatic decrease in learnable parameters by leveraging symmetries in data and architecture design. These enabling properties arise from the equivariance property of convolutions. In this module you will learn how to equip neural networks with equivariance properties. The module is split in 4 lectures with accompanying tutorials: This module is split into 4 lectures: <ul><li> <b>Lecture 1</b>: Regular group convolutional neural networks (G-CNNs). In this lecture we cover the basics of group convolutional NNs and show how to leverage symmetries in data and practical problems.</li>  <li> <b>Lecture 2</b>: Steerable G-CNNs. In this lecture we introduce a very general class of G-CNNs that allows to handle (rotational) symmetries in a flexible and powerful way. These methods are at the core of the most successful methods to handle 3D data such as atomic point clouds, but are also at the core of gauge equivariant methods that are applicable to arbitrary Riemannian manifolds.</li> <li> <b>Lecture 3</b>: Equivariant graph NNs. Many problems in computational chemistry and computational physics are now-a-days solved via graph NNs. The SotA in these domains derive their effectives from the geometric structure and symmetries presented by the data and underlying physics. In this lecture cover tools for SE(3) equivariance in the context of state-of-the-art in geometric graph NNs. </li> <li> <b>Lecture 4</b>: Recap and/or, if time allows, further exploration of topics covered in this module (e.g. equivariant transformers, geometric latent spaces, â€¦). </li> </ul> <br></br> All the lectures can be find here: https://uvagedl.github.io/</p>
                        <h4>Documents:</h4>
                        <div class="lecture-document-list">
                            No documents.
                        </div>
                        <h4>Lecture recordings:</h4>
                        <div class="lecture-document-list">
                            No recordings.
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="lecture-box" style="">
                <button type="button" class="lecture-collapsible"><span class="fa fa-2x fa-university text-primary"></span><span class="lecture-title">Second part: Deep probabilistic models</span></button>
                <div class="lecture-content">
                    <div class="padding-div">
                        <p class="text-muted" style="font-size: 12px"><b>Wilker Aziz Ferreira</b></p>
                        <p><b>Credits: 1pts</b><br></br> Many (if not most) advanced DL models are probabilistic models (or at the very least key aspects of their design and training are given probabilistic treatment). The focus of this module (or this part of the module) is to learn to prescribe probability distributions over complex sample spaces (discrete, continuous, structured), parameterise these distributions using NNs, and estimate model parameters to maximise (bounds on) likelihood via gradient descent. The goal is to get students to expand their toolbox, to see modelling ideas and estimation algorithms as modules they can compose (ie, VI is not exclusive to VAEs, VAEs are not necessarily built upon Gaussians, autoregressive models are not exclusive to one data type or another, reparameterisation is a general tool, MLE is a general tool, etc). We cover two main classes of models, depending on whether a key function (the likelihood function) can be assessed tractably given a set of observations and a parameter vector. <br></br> <b>TL;DR</b> In this module you learn to view data as a byproduct of probabilistic experiments. You will parameterise joint probability distributions over observed random variables, however complex/structured they may be, and perform parameter estimation by regularised gradient-based maximum likelihood estimation. </br> <br><b>Relationship to other modules:</b></br> <ul><li>Advanced generative models are (rather special) instances of probabilistic models, this module gives you some background knowledge that can ease your way into advanced generative models such as normalising flows, energy-based models and diffusion processes.</li> <li>Certain advanced probabilistic models (e.g., latent variable models) require techniques to approximate intractable computations in a principled manner, those techniques are discussed in the amortised variational inference module. Because amortised VI concerns probabilistic models, this module can be thought of as background to it.</li><li>Bayesian models are also probabilistic, but you don't necessarily need to content of this module to understand Bayesian deep learning (it does help, but you can live without).</li></ul></p>
                        <h4>Documents:</h4>
                        <div class="lecture-document-list">
                            No documents.
                        </div>
                        <h4>Lecture recordings:</h4>
                        <div class="lecture-document-list">
                            No recordings.
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="lecture-box" style="margin-bottom: 40px;">
                <button type="button" class="lecture-collapsible"><span class="fa fa-2x fa-university text-primary"></span><span class="lecture-title">Third part: Neural Networks Dynamical Systems</span></button>
                <div class="lecture-content">
                    <div class="padding-div">
                        <p class="text-muted" style="font-size: 12px"><b>Efstratios Gavves</b></p>
                        <p><b>Credits: 1pts </b> <br></br> In this module we will study the interface and overlap between neural networks, dynamical systems, ordinary/partial/stochastic differential equations, and physics-based neural networks. We will study how and where dynamical systems be found in neural networks with implicit functions and neural ODEs. We will also see how neural networks can be used to model dynamical systems like Navier-Stokes with physics-informed neural networks, as well as with Fourier-inspired architectures and autoregressive neural networks.</p>
                        <h4>Documents:</h4>
                        <div class="lecture-document-list">
                            No documents.
                        </div>
                        <h4>Lecture recordings:</h4>
                        <div class="lecture-document-list">
                            No recordings.
                        </div>
                    </div>
                </div>
            </div>

        </div>
    </section>

    <div class="divider"></div>

    <section id="practicals">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Tutorials</h2>
                    <hr class="primary">
                </div>
            </div>

            <div class="lecture-box">
                <button type="button" class="lecture-collapsible"><span class="fa fa-2x fa-desktop text-primary"></span><span class="lecture-title">Topic: Group equivariant deep learning</span></button>
                <div class="lecture-content">
                    <div class="padding-div">
                        <table><tr><td style="width: 100%; margin: auto;">
                            <p class="text-muted" style="font-size: 12px">Deadline: <!--$$DEADLINE$$--></p>
                            <p>This module covers the topic of geometric deep learning, touching upon all its five G's (Grids, Groups, Graphs, Geodesics, and Gauges) but with a strong focus on group equivariant deep learning. The impact that CNNs made in fields such as computer vision, computational chemistry and physics, can largely be attributed to the fact that convolutions allow for weight sharing, geometric stability, and a dramatic decrease in learnable parameters by leveraging symmetries in data and architecture design. These enabling properties arise from the equivariance property of convolutions. In this module you will learn how to equip neural networks with equivariance properties.</p>
                            <h4>Tutorials:</h4>
                            <div class="lecture-document-list">
                                No documents.
                            </div>
                            <h4>Lecture recordings:</h4>
                            <div class="lecture-document-list">
                                Recordings will be added soon.
                            </div>
                        </td><td>
                            <img src="<!--$$IMAGE$$-->" alt="" width="300" style="padding-bottom: 10px"></br>
                            <center class="text-muted" style="font-size: 12px"><!--$$IMAGE_DESC$$--></center>
                        </td></tr></table>
                    </div>
                </div>
            </div>
            
            <div class="lecture-box">
                <button type="button" class="lecture-collapsible"><span class="fa fa-2x fa-desktop text-primary"></span><span class="lecture-title">Topic: Deep probabilistic models</span></button>
                <div class="lecture-content">
                    <div class="padding-div">
                        <table><tr><td style="width: 100%; margin: auto;">
                            <p class="text-muted" style="font-size: 12px">Deadline: <!--$$DEADLINE$$--></p>
                            <p>Many (if not most) advanced DL models are probabilistic models (or at the very least key aspects of their design and training are given probabilistic treatment). The focus of this module (or this part of the module) is to learn to prescribe probability distributions over complex sample spaces (discrete, continuous, structured), parameterise these distributions using NNs, and estimate model parameters to maximise (bounds on) likelihood via gradient descent. The goal is to get students to expand their toolbox, to see modelling ideas and estimation algorithms as modules they can compose (ie, VI is not exclusive to VAEs, VAEs are not necessarily built upon Gaussians, autoregressive models are not exclusive to one data type or another, reparameterisation is a general tool, MLE is a general tool, etc). We cover two main classes of models, depending on whether a key function (the likelihood function) can be assessed tractably given a set of observations and a parameter vector. <br></br> <b>TL;DR</b> In this module you learn to view data as a byproduct of probabilistic experiments. You will parameterise joint probability distributions over observed random variables, however complex/structured they may be, and perform parameter estimation by regularised gradient-based maximum likelihood estimation. </br> <br><b>Relationship to other modules:</b></br> <ul><li>Advanced generative models are (rather special) instances of probabilistic models, this module gives you some background knowledge that can ease your way into advanced generative models such as normalising flows, energy-based models and diffusion processes.</li> <li>Certain advanced probabilistic models (e.g., latent variable models) require techniques to approximate intractable computations in a principled manner, those techniques are discussed in the amortised variational inference module. Because amortised VI concerns probabilistic models, this module can be thought of as background to it.</li><li>Bayesian models are also probabilistic, but you don't necessarily need to content of this module to understand Bayesian deep learning (it does help, but you can live without).</li></ul></p>
                            <h4>Tutorials:</h4>
                            <div class="lecture-document-list">
                                No documents.
                            </div>
                            <h4>Lecture recordings:</h4>
                            <div class="lecture-document-list">
                                No recordings.
                            </div>
                        </td><td>
                            <img src="<!--$$IMAGE$$-->" alt="" width="300" style="padding-bottom: 10px"></br>
                            <center class="text-muted" style="font-size: 12px"><!--$$IMAGE_DESC$$--></center>
                        </td></tr></table>
                    </div>
                </div>
            </div>
            
            <div class="lecture-box">
                <button type="button" class="lecture-collapsible"><span class="fa fa-2x fa-desktop text-primary"></span><span class="lecture-title">Topic: Neural Networks Dynamical Systems</span></button>
                <div class="lecture-content">
                    <div class="padding-div">
                        <table><tr><td style="width: 100%; margin: auto;">
                            <p class="text-muted" style="font-size: 12px">Deadline: <!--$$DEADLINE$$--></p>
                            <p>In this module we will study the interface and overlap between neural networks, dynamical systems, ordinary/partial/stochastic differential equations, and physics-based neural networks. We will study how and where dynamical systems be found in neural networks with implicit functions and neural ODEs. We will also see how neural networks can be used to model dynamical systems like Navier-Stokes with physics-informed neural networks, as well as with Fourier-inspired architectures and autoregressive neural networks.</p>
                            <h4>Tutorials:</h4>
                            <div class="lecture-document-list">
                                No documents.
                            </div>
                            <h4>Lecture recordings:</h4>
                            <div class="lecture-document-list">
                                No recordings.
                            </div>
                        </td><td>
                            <img src="<!--$$IMAGE$$-->" alt="" width="300" style="padding-bottom: 10px"></br>
                            <center class="text-muted" style="font-size: 12px"><!--$$IMAGE_DESC$$--></center>
                        </td></tr></table>
                    </div>
                </div>
            </div>

        </div>

    </section>


    <section id="course-links" class="bg-dark">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading">Links</h2>
                    <hr class="primary">
                    <p style="text-align:justify; font-size:18px;">Some useful links for the course are the following:

                    <p>
                    <div align="left">

                    <ul>

                    <li> <a href="https://piazza.com/class/l136xghmlo16ai" target="_blank" style="font-size:16px;"> Piazza </a></li>
                    
                    <li> <a href="https://datanose.nl/#course[120667]" target="_blank" style="font-size:16px;"> Datanose </a></li>

                    <li> <a href="https://canvas.uva.nl/courses/42571" target="_blank" style="font-size:16px;"> Canvas </a></li>

                    <!-- <li> <a href="https://probabll.github.io/teaching/probdl/," target="_blank" style="font-size:16px;"> Deep probabilistic models </a></li> -->

                    <li> <a href="https://www.youtube.com/channel/UCxf_K59uNpwBs-O67MT50-A/playlists," target="_blank" style="font-size:16px;"> YouTube channel </a></li>
                    </ul>

                    </div>
                    </p>

                </div>
            </div>
        </div>
    </section>

    <section class="bg-dark" id="old-lectures">
        <div class="container text-center">
            <div class="call-to-action">
                <h2>If you are interested in older versions of the lectures, you can find them below.</h2>

                <!-- <a href="lectures-feb2016.html#" class="btn btn-default btn-xl wow" target="_blank">UVADLC Feb 2016</a> -->
                <!-- <a href="lectures-nov2016.html#" class="btn btn-default btn-xl wow" target="_blank">UVADLC Nov 2016</a> -->
                <a href="lectures-2022.html#" class="btn btn-default btn-xl wow" target="_blank">UVADLC Nov 2023</a>
                <a href="lectures-2022.html#" class="btn btn-default btn-xl wow" target="_blank">UVADLC Nov 2022</a>
            </div>
        </div>
    </section>

    <section id="contact">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading">Contact us!</h2>
                    <hr class="primary">
                    <p class="running-text" style="text-align:justify">
                    If you have any questions or recommendations for the website or the course, you can always drop us a line!
                    The knowledge should be free, so feel also free to use any of the material provided here (but please be so kind to cite us).
                    In case you are a course instuctor and you want the solutions, please send us an email.
                    </p>
                </div>
                <div class="col-lg-4 col-lg-offset-2 text-center">
                    <i class="fa fa-map-marker fa-3x wow bounceIn"></i>
                    <p><a href="https://goo.gl/maps/HzB8CMdkTDA2">Room C3.229, Science Park 904 1098 XH, Amsterdam, The Netherlands</a></p>
                </div>
                <div class="col-lg-4 text-center">
                    <i class="fa fa-envelope-o fa-3x wow bounceIn" data-wow-delay=".1s"></i>
                    <p><a href="mailto:e.gavves@uva.nl">e.gavves@uva.nl</a></p>
                </div>
            </div>
        </div>
    </section>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="js/jquery.easing.min.js"></script>
    <script src="js/jquery.fittext.js"></script>
    <script src="js/wow.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/creative.js"></script>
    <script src="js/collapsible.js"></script>

</body>

</html>
